@misc{zhou2019dualattentionlocalization,
 abstract = {The research on recognizing the most discriminative regions provides referential information for weakly supervised object localization with only image-level annotations. However, the most discriminative regions usually conceal the other parts of the object, thereby impeding entire object recognition and localization. To tackle this problem, the Dual-attention Focused Module (DFM) is proposed to enhance object localization performance. Specifically, we present a dual attention module for information fusion, consisting of a position branch and a channel one. In each branch, the input feature map is deduced into an enhancement map and a mask map, thereby highlighting the most discriminative parts or hiding them. For the position mask map, we introduce a focused matrix to enhance it, which utilizes the principle that the pixels of an object are continuous. Between these two branches, the enhancement map is integrated with the mask map, aiming at partially compensating the lost information and diversifies the features. With the dual-attention module and focused matrix, the entire object region could be precisely recognized with implicit information. We demonstrate outperforming results of DFM in experiments. In particular, DFM achieves state-of-the-art performance in localization accuracy in ILSVRC 2016 and CUB-200-2011.},
 author = {Zhou, Y and Chen, Z and Shen, H and Liu, Q and Zhao, R and Liang, Y},
 day = {11},
 language = {English},
 month = {Sep},
 note = {This work is licensed under an Attribution 4.0 International License (CC BY 4.0).},
 publicationstatus = {published},
 publisher = {ArXiv},
 title = {Dual-attention Focused Module for Weakly Supervised Object Localization},
 url = {https://doi.org/10.48550/arXiv.1909.04813},
 year = {2019}
}
