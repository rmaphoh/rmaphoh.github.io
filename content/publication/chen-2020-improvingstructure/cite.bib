@inproceedings{chen2020improvingstructure,
 abstract = {Most previous knowledge distillation frameworks train the student to mimic the teacherâ€™s output of each sample or transfer cross-sample relations from the teacher to the student. Nevertheless, they neglect the structured relations at a category level. In this paper, a novel Category Structure is proposed to transfer category-level structured relations for knowledge distillation. It models two structured relations, including intra-category structure and inter-category structure, which are intrinsic natures in relations between samples. Intra-category structure penalizes the structured relations in samples from the same category and inter-category structure focuses on cross-category relations at a category level. Transferring category structure from the teacher to the student supplements category-level structured relations for training a better student. Extensive experiments show that our method groups samples from the same category tighter in the embedding space and the superiority of our method in comparison with closely related works are validated in different datasets and models.},
 author = {Chen, Z and Zheng, X and Shen, H and Zeng, Z and Zhou, Y and Zhao, R},
 booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
 day = {1},
 doi = {10.1007/978-3-030-58604-1_13},
 eissn = {1611-3349},
 issn = {0302-9743},
 month = {Jan},
 pages = {205--219},
 publicationstatus = {published},
 title = {Improving Knowledge Distillation via Category Structure},
 volume = {12373 LNCS},
 year = {2020}
}
