@misc{zhou2025revealingmodels,
 abstract = {<title>Abstract</title>
<p>Medical foundation models (FM), pre-trained on large-scale unlabelled data, have demonstrated robust performance and high efficiency when fine-tuned to various clinically relevant applications. However, the impact of pre-training data on medical FM performance such as generalisability and fairness, which form the foundation in fine-tuned models, remains unexplored. To address this, we sampled two large cohorts from two sites, Moorfields Eye Hospital (UK) and the Shanghai Diabetes Prevention Program (China), each containing 904,170 retinal images for FM pre-training. We developed parallel FMs using identical processes and compared their fairness and generalisability on downstream tasks with publicly available datasets and held-out data from each site. Our results demonstrate that, despite strong generalisability, medical FMs perform significantly better on downstream data that align with the pre-training data in approximately one-third of tasks. Additionally, age is a key metadata factor impacting FM fairness and generalisability in retinal images, whereas sex and ethnicity show no such impact. These findings advocate for an evidence-based approach to pre-training data selection and highlight the importance of transparency even for pre-training data, ultimately enhancing FM capabilities and guiding FM development and customised application in healthcare.</p>},
 author = {Zhou, Y and Wang, Z and Wu, Y and Ong, AY and Wagner, S and Ruffell, E and Chia, M and Guan, Z and Ju, L and Engelmann, J and Merle, D and Li, T and Shu, J and Nderitu, P and Zou, K and Goh, JHL and Hou, Q and Liu, X and Wang, Y and Tham, YC and Altmann, A and Cheung, C and Alexander, D and Topol, E and Denniston, A and Wong, TY and Sheng, B and Keane, PA},
 day = {3},
 doi = {10.21203/rs.3.rs-6080254/v1},
 month = {Apr},
 publicationstatus = {published},
 title = {Revealing the Impact of Pre-training Data on Medical Foundation Models},
 url = {https://doi.org/10.21203/rs.3.rs-6080254/v1},
 year = {2025}
}
