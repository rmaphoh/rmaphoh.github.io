@article{chen2025independentphotography,
author = {Chen, MS and Ravindranath, R and Chang, R and Zhou, Y and Keane, PA and Wang, SY},
journal = {OPHTHALMOLOGY SCIENCE},
month = {Jun},
number = {3},
publisher = {ELSEVIER},
title = {Independent Evaluation of RETFound Foundation Model's Performance on Optic Nerve Analysis Using Fundus Photography},
volume = {5},
year = {2025},
doi = {10.1016/j.xops.2025.100720},
issn = {2666-9145},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
keyword = {Artificial intelligence},
keyword = {Foundation model},
keyword = {Fundus photography},
keyword = {Glaucoma},
keyword = {FIBER LAYER THICKNESS},
keyword = {GLAUCOMA},
language = {English},
publicationstatus = {accepted},
}
@misc{zhou2025revealingmodels,
author = {Zhou, Y and Wang, Z and Wu, Y and Ong, AY and Wagner, S and Ruffell, E and Chia, M and Guan, Z and Ju, L and Engelmann, J and Merle, D and Li, T and Shu, J and Nderitu, P and Zou, K and Goh, JHL and Hou, Q and Liu, X and Wang, Y and Tham, YC and Altmann, A and Cheung, C and Alexander, D and Topol, E and Denniston, A and Wong, TY and Sheng, B and Keane, PA},
month = {Apr},
title = {Revealing the Impact of Pre-training Data on Medical Foundation Models},
url = {https://doi.org/10.21203/rs.3.rs-6080254/v1},
year = {2025},
abstract = {<title>Abstract</title>
        <p>Medical foundation models (FM), pre-trained on large-scale unlabelled data, have demonstrated robust performance and high efficiency when fine-tuned to various clinically relevant applications. However, the impact of pre-training data on medical FM performance such as generalisability and fairness, which form the foundation in fine-tuned models, remains unexplored. To address this, we sampled two large cohorts from two sites, Moorfields Eye Hospital (UK) and the Shanghai Diabetes Prevention Program (China), each containing 904,170 retinal images for FM pre-training. We developed parallel FMs using identical processes and compared their fairness and generalisability on downstream tasks with publicly available datasets and held-out data from each site. Our results demonstrate that, despite strong generalisability, medical FMs perform significantly better on downstream data that align with the pre-training data in approximately one-third of tasks. Additionally, age is a key metadata factor impacting FM fairness and generalisability in retinal images, whereas sex and ethnicity show no such impact. These findings advocate for an evidence-based approach to pre-training data selection and highlight the importance of transparency even for pre-training data, ultimately enhancing FM capabilities and guiding FM development and customised application in healthcare.</p>},
doi = {10.21203/rs.3.rs-6080254/v1},
day = {3},
publicationstatus = {published},
}
@article{eid2025retinaldataset,
author = {Eid, P and Bourredjem, A and Anwer, A and Creuzot-Garcher, C and Keane, PA and Zhou, Y and Wagner, S and Meriaudeau, F and Arnould, L},
journal = {Translational Vision Science and Technology},
month = {Mar},
number = {3},
title = {Retinal Microvascular Biomarker Assessment With Automated Algorithm and Semiautomated Software in the Montrachet Dataset},
volume = {14},
year = {2025},
abstract = {Purpose: To compare automated and semiautomated methods for the measurement of retinal microvascular biomarkers: the automated retinal vascular morphology (AutoMorph) algorithm and the Singapore “I” Vessel Assessment (SIVA) software. Methods: Analysis of retinal fundus photographs centered on optic discs from the population-based Montrachet Study of adults aged 75 years and older. Comparison and agreement evaluation with intraclass correlation coefficients (ICCs) between SIVA and AutoMorph measures of the central retinal venular and arteriolar equivalent, arteriolar–venular ratio, and fractal dimension. Results: Overall, 1069 fundus photographs were included in this study. The mean age of the patients was 80.04 ± 3.94 years. After the image quality grading process with an optimal threshold, the lowest rejection rate was 51.17\% for the AutoMorph analysis (n = 522). The measure of agreement between SIVA and AutoMorph retinal microvascular biomarkers showed a good correlation for vascular complexity (ICC, 0.77–0.47), a poor correlation for vascular calibers (ICC, 0.36–0.23), and no correlation for vascular tortuosity. Significant associations between retinal biomarkers and systemic variables (age, history of stroke, and systolic blood pressure) were consistent between SIVA and AutoMorph. Conclusions: In this dataset, AutoMorph presented a substantial rejection rate. SIVA and AutoMorph provided well-correlated measurements of vascular complexity and caliber with consistent clinical associations. Further comparisons are needed before a transition is made from semiautomated to automated algorithms for the analysis of retinal microvascular biomarkers. Translational Relevance: Open source software needs to be compared with former semiautomated software for retinal microvascular biomarkers assessment before transition in daily clinic and collaborative research.},
doi = {10.1167/tvst.14.3.13},
eissn = {2164-2591},
day = {1},
publicationstatus = {published},
}
@article{xiong2025howsettings,
author = {Xiong, Z and Wang, X and Zhou, Y and Keane, PA and Tham, YC and Wang, YX and Wong, TY},
journal = {NEJM AI},
month = {Jan},
publisher = {Massachusetts Medical Society},
title = {How Generalizable Are Foundation Models When Applied to Different Demographic Groups and Settings?},
url = {https://doi.org/10.1056/aics2400497},
year = {2025},
doi = {10.1056/aics2400497},
issn = {2836-9386},
language = {en},
publicationstatus = {published},
}
@article{chia2024aprediction,
author = {Chia, MA and Zhou, Y and Keane, PA},
journal = {NEJM AI},
month = {Nov},
number = {12},
publisher = {Massachusetts Medical Society},
title = {A New Foundation Model for Multimodal Ophthalmic Images: Advancing Disease Detection and Prediction},
url = {https://doi.org/10.1056/aie2401024},
volume = {1},
year = {2024},
doi = {10.1056/aie2401024},
issn = {2836-9386},
language = {en},
day = {27},
publicationstatus = {published},
}
@article{giesser2024evaluatingautomorph,
author = {Giesser, SD and Turgut, F and Saad, A and Zoellin, JR and Sommer, C and Zhou, Y and Wagner, SK and Keane, PA and Becker, M and DeBuc, DC and Somfai, GM},
howpublished = {Print},
journal = {Investigative Ophthalmology \& Visual Science},
month = {Nov},
note = {This work is licensed under a Creative Commons License. The images
or other third-party material in this article are included in the Creative Commons license,
unless indicated otherwise in the credit line; if the material is not included under the Creative Commons license,
users will need to obtain permission from the license holder to reproduce the material. To view a copy of this
license, visit http://creativecommons.org/licenses/by/4.0/},
number = {13},
organization = {United States},
publisher = {Association for Research in Vision and Ophthalmology (ARVO)},
title = {Evaluating the Impact of Retinal Vessel Segmentation Metrics on Retest Reliability in a Clinical Setting: A Comparative Analysis Using AutoMorph},
url = {http://dx.doi.org/10.1167/iovs.65.13.24},
volume = {65},
year = {2024},
abstract = {Purpose: Current research on artificial intelligence-based fundus photography biomarkers has demonstrated inconsistent results. Consequently, we aimed to evaluate and predict the test-retest reliability of retinal parameters extracted from fundus photography. Methods: Two groups of patients were recruited for the study: an intervisit group (n = 28) to assess retest reliability over a period of 1 to 14 days and an intravisit group (n = 44) to evaluate retest reliability within a single session. Using AutoMorph, we generated test and retest vessel segmentation maps; measured segmentation map agreement via accuracy, sensitivity, F1 score and Jaccard index; and calculated 76 metrics from each fundus image. The retest reliability of each metric was analyzed in terms of the Spearman correlation coefficient, intraclass correlation coefficient (ICC), and relative percentage change. A linear model with the input variables contrast-to-noise-ratio and fractal dimension, chosen by a P-value-based backward selection process, was developed to predict the median percentage difference on retest per image based on image-quality metrics. This model was trained on the intravisit dataset and validated using the intervisit dataset. Results: In the intervisit group, retest reliability varied between Spearman correlation coefficients of 0.34 and 0.99, ICC values of 0.31 to 0.99, and mean absolute percentage differences of 0.96\% to 223.67\%. Similarly, in the intravisit group, the retest reliability ranged from Spearman correlation coefficients of 0.55 and 0.96, ICC values of 0.40 to 0.97, and mean percentage differences of 0.49\% to 371.23\%. Segmentation map accuracy between test and retest never dropped below 97\%; the mean F1 scores were 0.85 for the intravisit dataset and 0.82 for the intervisit dataset. The best retest was achieved with disc-width regarding the Spearman correlation coefficient in both datasets. In terms of the Spearman correlation coefficient, the worst retests of the intervisit and intravisit groups were tortuosity density and artery tortuosity density, respectively. The intravisit group exhibited better retest reliability than the intervisit group (P < 0.001). Our linear model, with the two independent variables contrast-to-noise ratio and fractal dimension predicted the median retest reliability per image on its validation dataset, the intervisit group, with an R2 of 0.53 (P < 0.001). Conclusions: Our findings highlight a considerable volatility in the reliability of some retinal biomarkers. Improving retest could allow disease progression modeling in smaller datasets or an individualized treatment approach. Image quality is moderately predictive of retest reliability, and further work is warranted to understand the reasons behind our observations better and thus ensure consistent retest results.},
doi = {10.1167/iovs.65.13.24},
keyword = {Humans},
keyword = {Reproducibility of Results},
keyword = {Retinal Vessels},
keyword = {Photography},
keyword = {Female},
keyword = {Male},
keyword = {Middle Aged},
keyword = {Artificial Intelligence},
keyword = {Aged},
keyword = {Fundus Oculi},
keyword = {Image Processing},
keyword = {Computer-Assisted},
language = {English},
patentstatus = {},
pii = {2802240},
day = {4},
publicationstatus = {published},
}
@article{wei2024vcanmigration,
author = {Wei, R and Xie, H and Zhou, Y and Chen, X and Zhang, L and Bui, B and Liu, X},
journal = {FRONTIERS IN NEUROSCIENCE},
month = {Nov},
number = {ARTN 1501906},
publisher = {FRONTIERS MEDIA SA},
title = {VCAN in the extracellular matrix drives glioma recurrence by enhancing cell proliferation and migration},
volume = {18},
year = {2024},
doi = {10.3389/fnins.2024.1501906},
eissn = {1662-453X},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Neurosciences},
keyword = {Neurosciences \& Neurology},
keyword = {glioma},
keyword = {cancer recurrence},
keyword = {extracellular matrix},
keyword = {versican},
keyword = {PI3K/AKT pathway},
keyword = {VERSICAN},
keyword = {GLIOBLASTOMA},
keyword = {CILENGITIDE},
keyword = {EXPRESSION},
keyword = {PROMOTES},
language = {English},
day = {1},
publicationstatus = {published},
}
@article{giesser2024aanalyses,
author = {Giesser, SD and Turgut, F and Saad, A and Sommer, C and Zhou, Y and Wagner, SK and Keane, PA and Becker, M and Debuc, DC and Somfai, GM},
journal = {INVESTIGATIVE OPHTHALMOLOGY \& VISUAL SCIENCE},
month = {Oct},
number = {12},
publisher = {ASSOC RESEARCH VISION OPHTHALMOLOGY INC},
title = {A New Retest-Stable Tortuosity Metric for Retinal Vessel Analyses},
volume = {65},
year = {2024},
doi = {10.1167/iovs.65.12.30},
issn = {0146-0404},
eissn = {1552-5783},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
keyword = {tortuosity},
keyword = {retinal vasculature},
keyword = {fundus photography},
keyword = {mathematical modeling},
keyword = {deep learning},
language = {English},
publicationstatus = {published},
}
@article{chia2024foundationophthalmology,
author = {Chia, MA and Antaki, F and Zhou, Y and Turner, AW and Lee, AY and Keane, PA},
journal = {BRITISH JOURNAL OF OPHTHALMOLOGY},
month = {Oct},
number = {10},
pages = {1341--1348},
publisher = {BMJ PUBLISHING GROUP},
title = {Foundation models in ophthalmology},
volume = {108},
year = {2024},
doi = {10.1136/bjo-2024-325459},
issn = {0007-1161},
eissn = {1468-2079},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
keyword = {Retina},
keyword = {Imaging},
language = {English},
publicationstatus = {published},
}
@misc{hanumunthadu2024unveilingbiobank,
author = {Hanumunthadu, D and Reis, APR and Ioannidou, E and Wagner, S and Struyven, R and Zhou, Y and Foster, PJ and Khawaja, AP and Petzold, A and Pontikos, N and Keane, PA and Balaskas, K and Patel, PJ},
month = {Jun},
number = {7},
organization = {WA, Seattle},
publisher = {ASSOC RESEARCH VISION OPHTHALMOLOGY INC},
title = {Unveiling Patterns of Retinal Imaging: Association of Menopause with Choroidal Thickness and Retinovascular Indices in UK Biobank},
volume = {65},
year = {2024},
startyear = {2024},
startmonth = {May},
startday = {5},
finishyear = {2024},
finishmonth = {May},
finishday = {9},
issn = {0146-0404},
eissn = {1552-5783},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
language = {English},
conference = {Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology (ARVO)},
publicationstatus = {published},
}
@misc{patel2024retinovascularbiobank,
author = {Patel, PJ and Ioannidou, E and Wagner, S and Struyven, R and Zhou, Y and Foster, P and Khawaja, AP and Petzold, A and Pontikos, N and Keane, PA and Balaskas, K and Reis, APR},
month = {Jun},
number = {7},
organization = {WA, Seattle},
publisher = {ASSOC RESEARCH VISION OPHTHALMOLOGY INC},
title = {Retino-Vascular changes throughout the Menstrual Cycle: Associations with retinal imaging in UK Biobank},
volume = {65},
year = {2024},
startyear = {2024},
startmonth = {May},
startday = {5},
finishyear = {2024},
finishmonth = {May},
finishday = {9},
issn = {0146-0404},
eissn = {1552-5783},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
language = {English},
conference = {Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology (ARVO)},
publicationstatus = {published},
}
@article{patel2024retinalcohort,
author = {Patel, S and Bredemeyer, O and Williamson, DJ and Struyven, RR and Zhou, Y and Denniston, AK and Petzold, A and Antoniades, CA and Keane, PA and Wagner, SK},
journal = {Biomarkers in Neuropsychiatry},
month = {Jun},
title = {Retinal morphological differences in atypical Parkinsonism: A cross-sectional analysis of the AlzEye cohort},
volume = {10},
year = {2024},
abstract = {Objective: Atypical Parkinsonian syndrome (APS) describes a heterogeneous group of disorders mimicking the clinical presentation of Parkinson disease (PD) but with disparate natural history and pathophysiology. While retinal markers of PD are increasingly described, APS has been afforded less attention possibly owing to its lower prevalence. Here, we investigate retinal morphological differences in individuals with APS in a large real world cohort. Methods: We conducted a cross-sectional analysis of the AlzEye study, a retrospective cohort where ophthalmic data of individuals attending Moorfields Eye Hospital between January 2008 and March 31st 2018 (inclusive) has been linked with systemic disease data through national hospital admissions. Retinal features were extracted from macula-centered color fundus photography (CFP) and optical coherence tomography (OCT) and compared between individuals with APS and those unaffected. Individuals with idiopathic PD were excluded. Retinal neural and vascular features were measured using automated segmentation and analyzed with multivariable-adjusted regression models. Results: Among a cohort of 91,170 patients, there were 51 patients with APS and 91,119 controls. Individuals with APS were older and more likely to have hypertension and diabetes mellitus. After adjusting for age, sex, hypertension and diabetes melitus, individuals with APS had a thinner ganglion cell-inner plexiform layer (-3.95 microns, 95\% CI: −7.53, −0.37, p = 0.031) but no difference in other retinoneural or retinovascular indices. Optic nerve cup-to-disc ratio was similar between groups. Conclusion: Our cross-sectional analysis of the AlzEye cohort reveals distinct retinal morphological characteristics in APS compared to healthy controls. The study notably identifies a thinner ganglion cell-inner plexiform layer in APS patients, without accompanying changes in the inner nuclear layer or significant alterations in retinovascular indices and optic nerve cup-disc ratio. These changes are distinct from those observed in PD, where thinning of the inner nuclear layer (INL) is a characteristic feature. Significance: These findings demonstrate a retinal phenotype in APS, markedly different from both healthy controls and idiopathic Parkinson's disease, highlighting the potential of retinal imaging in differentiating neurodegenerative disorders. By establishing a distinct retinal phenotype for APS, our findings underscore the potential of retinal imaging as a valuable, non-invasive diagnostic tool. This advancement is particularly significant for enhancing diagnostic accuracy, facilitating early detection, and offering a window into the underlying disease mechanisms in APS, thereby aiding in the development of targeted therapeutic interventions and personalized patient care strategies.},
doi = {10.1016/j.bionps.2024.100096},
eissn = {2666-1446},
day = {1},
publicationstatus = {published},
}
@misc{raja2024retinalcohort,
author = {Raja, L and Patel, S and Williamson, D and Struyven, R and Zhou, Y and Denniston, A and Petzold, A and Antoniades, C and Wagner, S and Keane, PA},
month = {Jun},
number = {7},
organization = {WA, Seattle},
publisher = {ASSOC RESEARCH VISION OPHTHALMOLOGY INC},
title = {Retinal morphological differences in atypical Parkinsonism: A crosssectional analysis of the AlzEye cohort},
volume = {65},
year = {2024},
startyear = {2024},
startmonth = {May},
startday = {5},
finishyear = {2024},
finishmonth = {May},
finishday = {9},
issn = {0146-0404},
eissn = {1552-5783},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
language = {English},
conference = {Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology (ARVO)},
publicationstatus = {published},
}
@misc{sevgi2024predictingmodel,
author = {Sevgi, M and Zhou, Y and Wagner, S and Williamson, D and Struyven, R and Patel, PJ and Petzold, A and Denniston, A and Rahi, J and Borja, MC and Keane, PA},
month = {Jun},
number = {7},
organization = {WA, Seattle},
publisher = {ASSOC RESEARCH VISION OPHTHALMOLOGY INC},
title = {Predicting aortic stenosis from colour fundus photographs from the AlzEye Study using a deep learning model},
volume = {65},
year = {2024},
startyear = {2024},
startmonth = {May},
startday = {5},
finishyear = {2024},
finishmonth = {May},
finishday = {9},
issn = {0146-0404},
eissn = {1552-5783},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
language = {English},
conference = {Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology (ARVO)},
publicationstatus = {published},
}
@misc{drira2024oculomicsimaging,
author = {Drira, I and Reis, APR and Wagner, S and Struyven, R and Williamson, D and Chia, M and Zhou, Y and Liu, T and Khawaja, AP and Petzold, A and Silverstein, S and Patel, PJ and Pontikos, N and Balaskas, K and Keane, PA},
month = {Jun},
number = {7},
organization = {WA, Seattle},
publisher = {ASSOC RESEARCH VISION OPHTHALMOLOGY INC},
title = {Oculomics in Bipolar Affective Disorder: Insights from Retinal Imaging},
volume = {65},
year = {2024},
startyear = {2024},
startmonth = {May},
startday = {5},
finishyear = {2024},
finishmonth = {May},
finishday = {9},
issn = {0146-0404},
eissn = {1552-5783},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
language = {English},
conference = {Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology (ARVO)},
publicationstatus = {published},
}
@misc{ju2024explorerecognition,
author = {Ju, L and Zhou, Y and Xia, P and Alexander, D and Keane, PA and Ge, Z},
month = {Jun},
number = {7},
organization = {WA, Seattle},
publisher = {ASSOC RESEARCH VISION OPHTHALMOLOGY INC},
title = {Explore Vision-Language Model with Hierarchical Information for Multiple Retinal Disease Recognition},
volume = {65},
year = {2024},
startyear = {2024},
startmonth = {May},
startday = {5},
finishyear = {2024},
finishmonth = {May},
finishday = {9},
issn = {0146-0404},
eissn = {1552-5783},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
language = {English},
conference = {Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology (ARVO)},
publicationstatus = {published},
}
@misc{zhou2024accelerateophthalmology,
author = {Zhou, Y and Ju, L and Chia, M and Wagner, S and Alexander, D and Keane, PA},
month = {Jun},
number = {7},
organization = {WA, Seattle},
publisher = {ASSOC RESEARCH VISION OPHTHALMOLOGY INC},
title = {Accelerate the pace toward open - source research for ophthalmology},
volume = {65},
year = {2024},
startyear = {2024},
startmonth = {May},
startday = {5},
finishyear = {2024},
finishmonth = {May},
finishday = {9},
issn = {0146-0404},
eissn = {1552-5783},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
language = {English},
conference = {Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology (ARVO)},
publicationstatus = {published},
}
@misc{giesser2024aphotography,
author = {Giesser, SD and Turgut, F and Saad, A and Sommer, C and Zhou, Y and Wagner, S and Keane, PA and Becker, M and DeBuc, DC and Somfai, GM},
month = {Jun},
number = {7},
organization = {WA, Seattle},
publisher = {ASSOC RESEARCH VISION OPHTHALMOLOGY INC},
title = {A Retest -Stable Vessel Tortuosiry Metric for Fundus Photography},
volume = {65},
year = {2024},
startyear = {2024},
startmonth = {May},
startday = {5},
finishyear = {2024},
finishmonth = {May},
finishday = {9},
issn = {0146-0404},
eissn = {1552-5783},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
language = {English},
conference = {Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology (ARVO)},
publicationstatus = {published},
}
@misc{khetrapal2024remotetrial,
author = {Khetrapal, P and Liu, Y and Ambler, G and Williams, N and Sridhar, A and Khan, MS and Ahmad, I and Charlesworth, P and Kotwal, S and Rowe, E and Hanchanale, V and McGrath, J and Vasdev, N and Zhou, Y and Catto, JWF and Drobnjak, I and Kelly, JD},
month = {May},
note = {Journal of Urology, Volume 211, Issue 5S},
organization = {San Antonio, Texas, USA},
title = {REMOTE DIGITAL SURVEILLANCE AND MACHINE LEARNING MODELLING TO PREDICT SURVIVAL FOLLOWING RADICAL CYSTECTOMY FOR BLADDER CANCER—A SECONDARY OUTCOME ANALYSIS OF THE IROC TRIAL},
url = {https://www.auajournals.org/doi/abs/10.1097/01.JU.0001008916.72488.6a.04},
year = {2024},
abstract = {INTRODUCTION AND OBJECTIVE:
Wearable devices allow for measurement of physical activity, potentially providing supplementary prognostic insights for predicting survival following radical cystectomy (RC), alongside commonly used conventional clinicopathological factors. The primary objective of this analysis is to assess the additional value of wearable device monitoring to pathological data in predicting survival.

METHODS:
The iROC randomised trial (NCT03049410) compared peri-operative recovery after intracorporeal robot-assisted RC (iRARC) vs open RC (ORC) for bladder cancer. Step-count data was collected using wrist-worn wearable devices, and maximum steps and average steps per day was calculated at baseline and 12 weeks post-RC. Stamina was measured using the 30 second chair-to-stand test at similar timepoints. Clinicopathological data and survival data was collected, and cross-sectional imaging was used to determine cancer recurrence.

RESULTS:
Among 338 patients in the iROC trial, 319 patients received RC. Overall survival following RC was 87\% (319-41/319) patients and RFS was 82\% (319-57/319) over a median follow-up of 33 months. Wearable device data was available for 165 patients for analysis. There was no significant reduction in maximum step-counts at baseline (mean 9388 , SD 4552) when compared with 3-months post-operatively (mean 8792, SD 4055). Using clinicopathological features including age, gender, BMI, pathological T-stage and surgical margin, we demonstrated an AUC of 74\% to predict RFS which improved slightly to 76\% on adding activity and stamina data. For prediction of OS, using clinicopathological features demonstrated an AUC of 71\%, which improved to 81\% with the addition of activity and stamina data. Kaplan Meier analysis with patients divided into low and high risk groups by the final model showed an increased PFS (99\% vs 59\%) and OS (98\% vs 53\%) in 33 months after surgery.

CONCLUSIONS:
Mobility data may offer information which could add value to traditional prognostic models for survival. With new wearable devices, activity data can be remotely collected alongside other biometric data such as heart rate which may further improve models to predict RFS and OS.

Source of Funding:
The Urology Foundation and The Champniss Foundation},
doi = {10.1097/01.JU.0001008916.72488.6a.04},
startyear = {2024},
startmonth = {May},
startday = {2},
finishyear = {2024},
finishmonth = {May},
finishday = {6},
conference = {AUA Annual Meeting},
day = {5},
publicationstatus = {published},
}
@article{xu2024expectationlabels,
author = {Xu, M and Zhou, Y and Jin, C and de Groot, M and Alexander, DC and Oxtoby, NP and Hu, Y and Jacob, J},
journal = {Medical Image Analysis},
month = {May},
note = {© 2024 The Author(s). Published by Elsevier B.V. under a Creative Commons license (http://creativecommons.org/licenses/by/4.0/).},
number = {103125},
publisher = {Elsevier BV},
title = {Expectation maximisation pseudo labels},
url = {http://dx.doi.org/10.1016/j.media.2024.103125},
volume = {94},
year = {2024},
abstract = {In this paper, we study pseudo-labelling. Pseudo-labelling employs raw inferences on unlabelled data as pseudo-labels for self-training. We elucidate the empirical successes of pseudo-labelling by establishing a link between this technique and the Expectation Maximisation algorithm. Through this, we realise that the original pseudo-labelling serves as an empirical estimation of its more comprehensive underlying formulation. Following this insight, we present a full generalisation of pseudo-labels under Bayes’ theorem, termed Bayesian Pseudo Labels. Subsequently, we introduce a variational approach to generate these Bayesian Pseudo Labels, involving the learning of a threshold to automatically select high-quality pseudo labels. In the remainder of the paper, we showcase the applications of pseudo-labelling and its generalised form, Bayesian Pseudo-Labelling, in the semi-supervised segmentation of medical images. Specifically, we focus on: (1) 3D binary segmentation of lung vessels from CT volumes; (2) 2D multi-class segmentation of brain tumours from MRI volumes; (3) 3D binary segmentation of whole brain tumours from MRI volumes; and (4) 3D binary segmentation of prostate from MRI volumes. We further demonstrate that pseudo-labels can enhance the robustness of the learned representations. The code is released in the following GitHub repository: https://github.com/moucheng2017/EMSSL.},
doi = {10.1016/j.media.2024.103125},
keyword = {Pseudo labels},
keyword = {Bayesian deep learning},
keyword = {Expectation–maximisation},
keyword = {Semi-supervised learning},
keyword = {Segmentation},
keyword = {Generative models},
keyword = {Robustness},
language = {English},
publicationstatus = {published},
}
@article{shi2024crossmodalityrisk,
author = {Shi, D and Zhou, Y and He, S and Wagner, SK and Huang, Y and Keane, PA and Ting, DSW and Zhang, L and Zheng, Y and He, M},
howpublished = {Electronic-eCollection},
journal = {Ophthalmology Science},
month = {May},
note = {© 2024 Published by Elsevier Inc. on behalf of the American Academy of 1
Ophthalmology. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).},
number = {3},
organization = {Netherlands},
publisher = {Elsevier BV},
title = {Cross-modality Labeling Enables Noninvasive Capillary Quantification as a Sensitive Biomarker for Assessing Cardiovascular Risk},
url = {http://dx.doi.org/10.1016/j.xops.2023.100441},
volume = {4},
year = {2024},
abstract = {PURPOSE: We aim to use fundus fluorescein angiography (FFA) to label the capillaries on color fundus (CF) photographs and train a deep learning model to quantify retinal capillaries noninvasively from CF and apply it to cardiovascular disease (CVD) risk assessment. DESIGN: Cross-sectional and longitudinal study. PARTICIPANTS: A total of 90732 pairs of CF-FFA images from 3893 participants for segmentation model development, and 49229 participants in the UK Biobank for association analysis. METHODS: We matched the vessels extracted from FFA and CF, and used vessels from FFA as labels to train a deep learning model (RMHAS-FA) to segment retinal capillaries using CF. We tested the model's accuracy on a manually labeled internal test set (FundusCapi). For external validation, we tested the segmentation model on 7 vessel segmentation datasets, and investigated the clinical value of the segmented vessels in predicting CVD events in the UK Biobank. MAIN OUTCOME MEASURES: Area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, and specificity for segmentation. Hazard ratio (HR; 95\% confidence interval [CI]) for Cox regression analysis. RESULTS: On the FundusCapi dataset, the segmentation performance was AUC = 0.95, accuracy = 0.94, sensitivity = 0.90, and specificity = 0.93. Smaller vessel skeleton density had a stronger correlation with CVD risk factors and incidence (P < 0.01). Reduced density of small vessel skeletons was strongly associated with an increased risk of CVD incidence and mortality for women (HR [95\% CI] = 0.91 [0.84-0.98] and 0.68 [0.54-0.86], respectively). CONCLUSIONS: Using paired CF-FFA images, we automated the laborious manual labeling process and enabled noninvasive capillary quantification from CF, supporting its potential as a sensitive screening method for identifying individuals at high risk of future CVD events. FINANCIAL DISCLOSURES: Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of this article.},
doi = {10.1016/j.xops.2023.100441},
issn = {2666-9145},
keyword = {Cardiovascular disease},
keyword = {Cross-modality labeling},
keyword = {RMHAS-FA},
keyword = {Retinal capillary quantification},
language = {English},
patentstatus = {},
pii = {S2666-9145(23)00173-2},
publicationstatus = {published},
}
@article{zhou2024cflossmeasurement,
author = {Zhou, Y and Xu, M and Hu, Y and Blumberg, SB and Zhao, A and Wagner, SK and Keane, PA and Alexander, DC},
journal = {Medical Image Analysis},
month = {Apr},
number = {103098},
pages = {103098--103098},
publisher = {Elsevier BV},
title = {CF-Loss: Clinically-relevant feature optimised loss function for retinal multi-class vessel segmentation and vascular feature measurement},
url = {http://dx.doi.org/10.1016/j.media.2024.103098},
volume = {93},
year = {2024},
doi = {10.1016/j.media.2024.103098},
issn = {1361-8415},
language = {en},
publicationstatus = {published},
}
@phdthesis{zhou2024generalisabledetection,
author = {Zhou, Y},
pages = {1--279},
school = {},
title = {Generalisable Retinal Image Analysis for Disease Detection},
year = {2024},
abstract = {Retinal anatomical tissues, including the nerve fibre layer and vasculature, provide a non-invasive view of central nervous system and microvascular system. The application of artificial intelligence (AI) in retinal image analysis holds significant promise in detecting indicators of health conditions within retinal images, facilitating the prompt diagnosis of eye diseases and systemic disorders. However, effective retinal image analysis necessitates the seamless integration of multiple AI models while developing such AI models requires substantial annotation efforts. Furthermore, these models often exhibit task-specific limitations with restricted generalisability across various clinical applications. 

This project aims to investigate the generalisable methods for retinal image analysis that contribute to diverse healthcare applications. We first present AutoMorph, an automated pipeline for quantifying retinal morphology. This pipeline includes image preprocessing, image quality assessment, anatomical tissue segmentation, and clinically relevant indices measurement. To enhance the multi-class vessel segmentation, we devise a multi-branch network with information fusion to reduce segmentation error and propose an indices-optimised regularisation to segment multi-class vessels that derive accurate indices. AutoMorph modules perform well even when external validation data shows domain differences from training data, e.g. with different imaging devices. This fully automated pipeline allows efficient quantitative analysis of retinal morphology, supporting the discovery of the retinal morphology manifestation under various health conditions.

Meanwhile, we present RETFound, a foundation model for retinal images that learns generalisable representations from unlabelled retinal images and provides a basis for label-efficient model adaptation in multiple disease detection. RETFound consistently enhances the diagnosis and prognosis of sight-threatening eye diseases, as well as incident prediction of complex systemic disorders such as myocardial infarction with limited labelled data. The fine-tuned models based on RETFound show good generalisability in external validation, with the data from different imaging devices and populations.

This project provides AutoMorph and RETFound to enable generalisable retinal image analysis that supports diverse healthcare applications. By making all the developed tools and models publicly available, we hope this facilitates researchers worldwide to build their own models and collectively contribute to the healthcare community.},
language = {English},
conference = {UCL (University College London)},
}
@article{wagner2023retinaldisease,
author = {Wagner, SK and Romero-Bascones, D and Cortina-Borja, M and Williamson, DJ and Struyven, RR and Zhou, Y and Patel, S and Weil, RS and Antoniades, CA and Topol, EJ and Korot, E and Foster, PJ and Balaskas, K and Ayala, U and Barrenechea, M and Gabilondo, I and Schapira, AH and Khawaja, AP and Patel, PJ and Rahi, JS and Denniston, AK and Petzold, A and Keane, PA and UK Biobank Eye \& Vision Consortium},
howpublished = {Print-Electronic},
journal = {Neurology},
month = {Oct},
note = {Copyright © 2023 The Author(s). This is an open access article distributed under the terms of the Creative Commons Attribution License 4.0 (CC BY), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
number = {16},
organization = {United States},
pages = {e1581--e1593},
publisher = {Ovid Technologies (Wolters Kluwer Health)},
title = {Retinal Optical Coherence Tomography Features Associated With Incident and Prevalent Parkinson Disease},
url = {http://doi.org/10.1212/WNL.0000000000207727},
volume = {101},
year = {2023},
abstract = {Background and objectives: Cadaveric studies have shown disease-related neurodegeneration and other morphological abnormalities in the retina of individuals with Parkinson disease (PD), however it remains unclear whether this can be reliably detected with in vivo imaging. We investigated inner retinal anatomy, measured using optical coherence tomography (OCT), in prevalent PD and subsequently assessed the association of these markers with the development of PD using a prospective research cohort.//

Methods: This cross-sectional analysis used data from two studies. For the detection of retinal markers in prevalent PD, we used data from AlzEye, a retrospective cohort of 154,830 patients aged 40 years and over attending secondary care ophthalmic hospitals in London, UK between 2008 and 2018. For the evaluation of retinal markers in incident PD, we used data from UK Biobank, a prospective population-based cohort where 67,311 volunteers aged 40-69 years were recruited between 2006 and 2010 and underwent retinal imaging. Macular retinal nerve fibre layer (mRNFL), ganglion cell-inner plexiform layer (GCIPL), and inner nuclear layer (INL) thicknesses were extracted from fovea--centred OCT. Linear mixed effects models were fitted to examine the association between prevalent PD and retinal thicknesses. Hazard ratios for the association between time to PD diagnosis and retinal thicknesses were estimated using frailty models.//

Results: Within the AlzEye cohort, there were 700 individuals with prevalent PD and 105,770 controls (mean age 65.5 ± 13.5 years, 51.7\% female). Individuals with prevalent PD had thinner GCIPL (-2.12 μm, 95\% confidence interval: -3.17, -1.07, p = 8.2 × 10⁻⁵) and INL (-0.99 μm, 95\% confidence interval: -1.52, -0.47, p = 2.1 × 10⁻⁴). The UK Biobank included 50,405 participants (mean age 56.1 ± 8.2 years, 54.7\% female), of whom 53 developed PD at a mean of 2653 ± 851 days. Thinner GCIPL (hazard ratio: 0.62 per standard deviation increase, 95\% confidence interval: 0.46, 0.84, p=0.002) and thinner INL (hazard ratio: 0.70, 95\% confidence interval: 0.51, 0.96, p=0.026) were also associated with incident PD.//

Discussion: Individuals with PD have reduced thickness of the INL and GCIPL of the retina. Involvement of these layers several years before clinical presentation highlight a potential role for retinal imaging for at-risk stratification of PD.},
doi = {10.1212/WNL.0000000000207727},
issn = {0028-3878},
language = {English},
pii = {WNL.0000000000207727},
day = {17},
publicationstatus = {published},
}
@article{zhou2023aimages,
author = {Zhou, Y and Chia, MA and Wagner, SK and Ayhan, MS and Williamson, DJ and Struyven, RR and Liu, T and Xu, M and Lozano, MG and Woodward-Court, P and Kihara, Y and UK Biobank Eye \& Vision Consortium and Altmann, A and Lee, AY and Topol, EJ and Denniston, AK and Alexander, DC and Keane, PA},
howpublished = {Print-Electronic},
journal = {Nature},
month = {Sep},
note = {This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.},
organization = {England},
publisher = {Springer Science and Business Media LLC},
title = {A foundation model for generalizable disease detection from retinal images},
url = {https://doi.org/10.1038/s41586-023-06555-x},
year = {2023},
abstract = {Medical artificial intelligence (AI) offers great potential for recognizing signs of health conditions in retinal images and expediting the diagnosis of eye diseases and systemic disorders1. However, the development of AI models requires substantial annotation and models are usually task-specific with limited generalizability to different clinical applications2. Here, we present RETFound, a foundation model for retinal images that learns generalizable representations from unlabelled retinal images and provides a basis for label-efficient model adaptation in several applications. Specifically, RETFound is trained on 1.6 million unlabelled retinal images by means of self-supervised learning and then adapted to disease detection tasks with explicit labels. We show that adapted RETFound consistently outperforms several comparison models in the diagnosis and prognosis of sight-threatening eye diseases, as well as incident prediction of complex systemic disorders such as heart failure and myocardial infarction with fewer labelled data. RETFound provides a generalizable solution to improve model performance and alleviate the annotation workload of experts to enable broad clinical AI applications from retinal imaging.},
doi = {10.1038/s41586-023-06555-x},
issn = {0028-0836},
language = {English},
pii = {10.1038/s41586-023-06555-x},
day = {13},
publicationstatus = {accepted},
}
@article{wagner2023commentneuropathy,
author = {Wagner, S and Zhou, Y and O'Byrne, C and Khawaja, A and Petzold, A and Keane, P},
journal = {American Journal of Ophthalmology},
month = {Jul},
publisher = {Elsevier Masson},
title = {Comment on "Race distribution in non-arteritic anterior ischemic optic neuropathy"},
year = {2023},
issn = {0002-9394},
day = {12},
publicationstatus = {published},
}
@misc{liu2023retinalindividuals,
author = {Liu, T and Wagner, S and Struyven, R and Zhou, Y and Williamson, D and Romero-Bascones, D and Lozano, MG and Pontikos, N and Patel, PJ and Borja, MC and Rahi, J and Petzold, A and Khawaja, AP and Denniston, AK and Balaskas, K and Keane, P},
month = {Jun},
number = {8},
organization = {LA, New Orleans},
publisher = {ASSOC RESEARCH VISION OPHTHALMOLOGY INC},
title = {Retinal biomarkers for systemic diseases: an oculome-wide association study in 164,784 individuals},
volume = {64},
year = {2023},
startyear = {2023},
startmonth = {Apr},
startday = {23},
finishyear = {2023},
finishmonth = {Apr},
finishday = {27},
issn = {0146-0404},
eissn = {1552-5783},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
language = {English},
conference = {Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology (ARVO)},
publicationstatus = {published},
}
@misc{zhou2023predictingstudy,
author = {Zhou, Y and Wagner, S and Chia, M and Williamson, D and Struyven, R and Liu, T and Petzold, A and Rahi, J and Borja, MC and Denniston, AK and Alexander, D and Keane, P},
month = {Jun},
number = {8},
organization = {LA, New Orleans},
publisher = {ASSOC RESEARCH VISION OPHTHALMOLOGY INC},
title = {Predicting major adverse cardiovascular events with colour fundus photograph in the AlzEye Study},
volume = {64},
year = {2023},
startyear = {2023},
startmonth = {Apr},
startday = {23},
finishyear = {2023},
finishmonth = {Apr},
finishday = {27},
issn = {0146-0404},
eissn = {1552-5783},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
language = {English},
conference = {Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology (ARVO)},
publicationstatus = {published},
}
@misc{chia2023opticalalzeye,
author = {Chia, M and Zhou, Y and Wagner, S and Williamson, D and Struyven, R and Petzold, A and Denniston, AK and Rahi, J and Borja, MC and Keane, P},
month = {Jun},
number = {8},
organization = {LA, New Orleans},
publisher = {ASSOC RESEARCH VISION OPHTHALMOLOGY INC},
title = {Optical coherence tomography for the prediction of major adverse cardiovascular events in AlzEye},
volume = {64},
year = {2023},
startyear = {2023},
startmonth = {Apr},
startday = {23},
finishyear = {2023},
finishmonth = {Apr},
finishday = {27},
issn = {0146-0404},
eissn = {1552-5783},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
language = {English},
conference = {Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology (ARVO)},
publicationstatus = {published},
}
@misc{struyven2023deeplearningalzeye,
author = {Struyven, RRR and Williamson, D and Wagner, S and Romero-Bascones, D and Zhou, Y and Liu, T and Wu, Y and Balaskas, K and Borja, MC and Rahi, J and Petzold, A and Lee, AY and Lee, CS and Denniston, AK and Alexander, D and Keane, P},
month = {Jun},
number = {8},
organization = {LA, New Orleans},
publisher = {ASSOC RESEARCH VISION OPHTHALMOLOGY INC},
title = {Deep-learning fusion of OCT imaging and traditional risk factors to improve dementia detection in AlzEye},
volume = {64},
year = {2023},
startyear = {2023},
startmonth = {Apr},
startday = {23},
finishyear = {2023},
finishmonth = {Apr},
finishday = {27},
issn = {0146-0404},
eissn = {1552-5783},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
language = {English},
conference = {Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology (ARVO)},
publicationstatus = {published},
}
@misc{raja2023associationsanalysis,
author = {Raja, L and Liu, T and Zhou, Y and Struyven, R and Williamson, D and Borja, M and Romero-Bascones, D and Khawaja, A and Patel, P and Alexander, D and Balaskas, K and Rahi, J and Denniston, A and Petzold, A and Wagner, S and Keane, P},
month = {Jun},
number = {8},
organization = {LA, New Orleans},
publisher = {ASSOC RESEARCH VISION OPHTHALMOLOGY INC},
title = {Associations of Retinal Vascular Morphology and Inflammatory Bowel Disease: A cross-sectional analysis.},
volume = {64},
year = {2023},
startyear = {2023},
startmonth = {Apr},
startday = {23},
finishyear = {2023},
finishmonth = {Apr},
finishday = {27},
issn = {0146-0404},
eissn = {1552-5783},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
language = {English},
conference = {Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology (ARVO)},
publicationstatus = {published},
}
@misc{wang2023agelearning,
author = {Wang, Y and Liu, T and Williamson, D and Struyven, R and Zhou, Y and Romero-Bascones, D and Lozano, MG and Balaskas, K and Borja, MC and Rahi, J and Petzold, A and Khawaja, AP and Denniston, AK and Wagner, S and Keane, P},
month = {Jun},
number = {8},
organization = {LA, New Orleans},
publisher = {ASSOC RESEARCH VISION OPHTHALMOLOGY INC},
title = {Age Prediction from Retinal Fundus Images and Segmented Vessel Images using Deep Learning},
volume = {64},
year = {2023},
startyear = {2023},
startmonth = {Apr},
startday = {23},
finishyear = {2023},
finishmonth = {Apr},
finishday = {27},
issn = {0146-0404},
eissn = {1552-5783},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
language = {English},
conference = {Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology (ARVO)},
publicationstatus = {published},
}
@article{xu2023mismatchlabels,
author = {Xu, MC and Zhou, Y and Jin, C and De Groot, M and Alexander, DC and Oxtoby, NP and Jacob, J},
journal = {IEEE Transactions on Medical Imaging},
month = {May},
title = {MisMatch: Calibrated Segmentation via Consistency on Differential Morphological Feature Perturbations with Limited Labels},
year = {2023},
abstract = {Semi-supervised learning (SSL) is a promising machine learning paradigm to address the ubiquitous issue of label scarcity in medical imaging. The state-of-the-art SSL methods in image classification utilise consistency regularisation to learn unlabelled predictions which are invariant to input level perturbations. However, image level perturbations violate the cluster assumption in the setting of segmentation. Moreover, existing image level perturbations are hand-crafted which could be sub-optimal. In this paper, we propose MisMatch, a semi-supervised segmentation framework based on the consistency between paired predictions which are derived from two differently learnt morphological feature perturbations. MisMatch consists of an encoder and two decoders. One decoder learns positive attention for foreground on unlabelled data thereby generating dilated features of foreground. The other decoder learns negative attention for foreground on the same unlabelled data thereby generating eroded features of foreground. We normalise the paired predictions of the decoders, along the batch dimension. A consistency regularisation is then applied between the normalised paired predictions of the decoders. We evaluate MisMatch on four different tasks. Firstly, we develop a 2D U-net based MisMatch framework and perform extensive cross-validation on a CT-based pulmonary vessel segmentation task and show that MisMatch statistically outperforms state-of-the-art semi-supervised methods. Secondly, we show that 2D MisMatch outperforms state-of-the-art methods on an MRI-based brain tumour segmentation task. We then further confirm that 3D V-net based MisMatch outperforms its 3D counterpart based on consistency regularisation with input level perturbations, on two different tasks including, left atrium segmentation from 3D CT images and whole brain tumour segmentation from 3D MRI images. Lastly, we find that the performance improvement of MisMatch over the baseline might originate from its better calibration. This also implies that our proposed AI system makes safer decisions than the previous methods.},
doi = {10.1109/TMI.2023.3273158},
issn = {0278-0062},
eissn = {1558-254X},
day = {8},
publicationstatus = {published},
}
@article{wagner2023associationschizophrenia,
author = {Wagner, SK and Cortina-Borja, M and Silverstein, SM and Zhou, Y and Romero-Bascones, D and Struyven, RR and Trucco, E and Mookiah, MRK and MacGillivray, T and Hogg, S and Liu, T and Williamson, DJ and Pontikos, N and Patel, PJ and Balaskas, K and Alexander, DC and Stuart, KV and Khawaja, AP and Denniston, AK and Rahi, JS and Petzold, A and Keane, PA},
journal = {JAMA Psychiatry},
month = {Mar},
organization = {United States},
publisher = {American Medical Association},
title = {Association Between Retinal Features From Multimodal Imaging and Schizophrenia.},
url = {https://www.ncbi.nlm.nih.gov/pubmed/36947045},
year = {2023},
abstract = {IMPORTANCE: The potential association of schizophrenia with distinct retinal changes is of clinical interest but has been challenging to investigate because of a lack of sufficiently large and detailed cohorts. OBJECTIVE: To investigate the association between retinal biomarkers from multimodal imaging (oculomics) and schizophrenia in a large real-world population. DESIGN, SETTING, AND PARTICIPANTS: This cross-sectional analysis used data from a retrospective cohort of 154 830 patients 40 years and older from the AlzEye study, which linked ophthalmic data with hospital admission data across England. Patients attended Moorfields Eye Hospital, a secondary care ophthalmic hospital with a principal central site, 4 district hubs, and 5 satellite clinics in and around London, United Kingdom, and had retinal imaging during the study period (January 2008 and April 2018). Data were analyzed from January 2022 to July 2022. MAIN OUTCOMES AND MEASURES: Retinovascular and optic nerve indices were computed from color fundus photography. Macular retinal nerve fiber layer (RNFL) and ganglion cell-inner plexiform layer (mGC-IPL) thicknesses were extracted from optical coherence tomography. Linear mixed-effects models were used to examine the association between schizophrenia and retinal biomarkers. RESULTS: A total of 485 individuals (747 eyes) with schizophrenia (mean [SD] age, 64.9 years [12.2]; 258 [53.2\%] female) and 100 931 individuals (165 400 eyes) without schizophrenia (mean age, 65.9 years [13.7]; 53 253 [52.8\%] female) were included after images underwent quality control and potentially confounding conditions were excluded. Individuals with schizophrenia were more likely to have hypertension (407 [83.9\%] vs 49 971 [48.0\%]) and diabetes (364 [75.1\%] vs 28 762 [27.6\%]). The schizophrenia group had thinner mGC-IPL (-4.05 μm, 95\% CI, -5.40 to -2.69; P = 5.4 × 10-9), which persisted when investigating only patients without diabetes (-3.99 μm; 95\% CI, -6.67 to -1.30; P = .004) or just those 55 years and younger (-2.90 μm; 95\% CI, -5.55 to -0.24; P = .03). On adjusted analysis, retinal fractal dimension among vascular variables was reduced in individuals with schizophrenia (-0.14 units; 95\% CI, -0.22 to -0.05; P = .001), although this was not present when excluding patients with diabetes. CONCLUSIONS AND RELEVANCE: In this study, patients with schizophrenia had measurable differences in neural and vascular integrity of the retina. Differences in retinal vasculature were mostly secondary to the higher prevalence of diabetes and hypertension in patients with schizophrenia. The role of retinal features as adjunct outcomes in patients with schizophrenia warrants further investigation.},
doi = {10.1001/jamapsychiatry.2023.0171},
issn = {2168-622X},
eissn = {2168-6238},
language = {eng},
pii = {2802551},
day = {22},
publicationstatus = {online-published},
}
@inproceedings{xu2022bayesiansegmentation,
author = {Xu, M-C and Zhou, Y and Jin, C and Groot, MD and Alexander, DC and Oxtoby, NP and Hu, Y and Jacob, J},
booktitle = {},
month = {Sep},
note = {MICCAI 2022 (Early accept, Student Travel Award)},
title = {Bayesian Pseudo Labels: Expectation Maximization for Robust and
  Efficient Semi-Supervised Segmentation},
url = {https://conferences.miccai.org/2022/en/CALL-FOR-PAPERS.html},
year = {2022},
abstract = {This paper concerns pseudo labelling in segmentation. Our contribution is
fourfold. Firstly, we present a new formulation of pseudo-labelling as an
Expectation-Maximization (EM) algorithm for clear statistical interpretation.
Secondly, we propose a semi-supervised medical image segmentation method purely
based on the original pseudo labelling, namely SegPL. We demonstrate SegPL is a
competitive approach against state-of-the-art consistency regularisation based
methods on semi-supervised segmentation on a 2D multi-class MRI brain tumour
segmentation task and a 3D binary CT lung vessel segmentation task. The
simplicity of SegPL allows less computational cost comparing to prior methods.
Thirdly, we demonstrate that the effectiveness of SegPL may originate from its
robustness against out-of-distribution noises and adversarial attacks. Lastly,
under the EM framework, we introduce a probabilistic generalisation of SegPL
via variational inference, which learns a dynamic threshold for pseudo
labelling during the training. We show that SegPL with variational inference
can perform uncertainty estimation on par with the gold-standard method Deep
Ensemble.},
doi = {10.1007/978-3-031-16443-9_56},
keyword = {cs.AI},
keyword = {cs.CV},
keyword = {cs.CV},
keyword = {cs.LG},
conference = {MICCAI 2022},
day = {18},
}
@inproceedings{zhao2022prognosticfibrosis,
author = {Zhao, A and Shahin, AH and Zhou, Y and Gudmundsson, E and Szmul, A and Mogulkoc, N and van Beek, F and Brereton, CJ and van Es, HW and Pontoppidan, K and Savas, R and Wallis, T and Unat, O and Veltkamp, M and Jones, MG and van Moorsel, CHM and Barber, D and Jacob, J and Alexander, DC},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
month = {Sep},
pages = {223--233},
title = {Prognostic Imaging Biomarker Discovery in Survival Analysis for Idiopathic Pulmonary Fibrosis},
volume = {13437 LNCS},
year = {2022},
abstract = {Imaging biomarkers derived from medical images play an important role in diagnosis, prognosis, and therapy response assessment. Developing prognostic imaging biomarkers which can achieve reliable survival prediction is essential for prognostication across various diseases and imaging modalities. In this work, we propose a method for discovering patch-level imaging patterns which we then use to predict mortality risk and identify prognostic biomarkers. Specifically, a contrastive learning model is first trained on patches to learn patch representations, followed by a clustering method to group similar underlying imaging patterns. The entire medical image can be thus represented by a long sequence of patch representations and their cluster assignments. Then a memory-efficient clustering Vision Transformer is proposed to aggregate all the patches to predict mortality risk of patients and identify high-risk patterns. To demonstrate the effectiveness and generalizability of our model, we test the survival prediction performance of our method on two sets of patients with idiopathic pulmonary fibrosis (IPF), a chronic, progressive, and life-threatening interstitial pneumonia of unknown etiology. Moreover, by comparing the high-risk imaging patterns extracted by our model with existing imaging patterns utilised in clinical practice, we can identify a novel biomarker that may help clinicians improve risk stratification of IPF patients.},
doi = {10.1007/978-3-031-16449-1_22},
isbn = {9783031164484},
issn = {0302-9743},
eissn = {1611-3349},
conference = {International Conference on Medical Image Computing and Computer-Assisted Intervention - MICCAI 2022:},
day = {17},
publicationstatus = {published},
}
@misc{xu2022bayesiansegmentation,
author = {Xu, M-C and Zhou, Y and Jin, C and Groot, MD and Alexander, DC and Oxtoby, NP and Hu, Y and Jacob, J},
month = {Aug},
title = {Bayesian Pseudo Labels: Expectation Maximization for Robust and Efficient Semi-Supervised Segmentation.},
url = {https://arxiv.org/abs/2208.04435},
url = {https://doi.org/10.48550/arXiv.2208.04435},
year = {2022},
doi = {10.48550/arXiv.2208.04435},
day = {8},
}
@inproceedings{xu2022learningsegmentation,
author = {Xu, M-C and Zhou, Y-K and Jin, C and Blumberg, SB and Wilson, FJ and deGroot, M and Alexander, DC and Oxtoby, NP and Jacob, J},
booktitle = {},
month = {Jul},
note = {Accepted at Conference on Medical Imaging with Deep Learning (MIDL)
  2022. arXiv admin note: text overlap with arXiv:2110.12179},
title = {Learning Morphological Feature Perturbations for Calibrated
  Semi-Supervised Segmentation},
url = {http://arxiv.org/abs/2203.10196v1},
url = {https://2022.midl.io/dates.html},
year = {2022},
abstract = {We propose MisMatch, a novel consistency-driven semi-supervised segmentation
framework which produces predictions that are invariant to learnt feature
perturbations. MisMatch consists of an encoder and a two-head decoders. One
decoder learns positive attention to the foreground regions of interest (RoI)
on unlabelled images thereby generating dilated features. The other decoder
learns negative attention to the foreground on the same unlabelled images
thereby generating eroded features. We then apply a consistency regularisation
on the paired predictions. MisMatch outperforms state-of-the-art
semi-supervised methods on a CT-based pulmonary vessel segmentation task and a
MRI-based brain tumour segmentation task. In addition, we show that the
effectiveness of MisMatch comes from better model calibration than its
supervised learning counterpart.},
conference = {5th Conference on Medical Imaging with Deep Learning (MIDL 2022)},
day = {8},
publicationstatus = {accepted},
}
@article{zhou2022automorphpipeline,
author = {Zhou, Y and Wagner, SK and Chia, MA and Zhao, A and Woodward-Court, P and Xu, M and Struyven, R and Alexander, DC and Keane, PA},
howpublished = {Print},
journal = {Translational Vision Science \& Technology},
month = {Jul},
note = {Copyright 2022 The Authors. This work is licensed under a Creative Commons Attribution 4.0 International License.},
number = {7},
organization = {United States},
publisher = {Association for Research in Vision and Ophthalmology (ARVO)},
title = {AutoMorph: Automated Retinal Vascular Morphology Quantification Via a Deep Learning Pipeline},
url = {https://doi.org/10.1167/tvst.11.7.12},
volume = {11},
year = {2022},
abstract = {Purpose: To externally validate a deep learning pipeline (AutoMorph) for automated analysis of retinal vascular morphology on fundus photographs. AutoMorph has been made publicly available, facilitating widespread research in ophthalmic and systemic diseases. Methods: AutoMorph consists of four functional modules: image preprocessing, image quality grading, anatomical segmentation (including binary vessel, artery/vein, and optic disc/cup segmentation), and vascular morphology feature measurement. Image quality grading and anatomical segmentation use the most recent deep learning techniques. We employ a model ensemble strategy to achieve robust results and analyze the prediction confidence to rectify false gradable cases in image quality grading. We externally validate the performance of each module on several independent publicly available datasets. Results: The EfficientNet-b4 architecture used in the image grading module achieves performance comparable to that of the state of the art for EyePACS-Q, with an F1-score of 0.86. The confidence analysis reduces the number of images incorrectly assessed as gradable by 76\%. Binary vessel segmentation achieves an F1-score of 0.73 on AV-WIDE and 0.78 on DR HAGIS. Artery/vein scores are 0.66 on IOSTAR-AV, and disc segmentation achieves 0.94 in IDRID. Vascular morphology features measured from the AutoMorph segmentation map and expert annotation show good to excellent agreement. Conclusions: AutoMorph modules perform well even when external validation data show domain differences from training data (e.g., with different imaging devices). This fully automated pipeline can thus allow detailed, efficient, and comprehensive analysis of retinal vascular morphology on color fundus photographs. Translational Relevance: By making AutoMorph publicly available and open source, we hope to facilitate ophthalmic and systemic disease research, particularly in the emerging field of oculomics.},
doi = {10.1167/tvst.11.7.12},
language = {English},
pii = {2783477},
day = {8},
publicationstatus = {published},
}
@misc{woodwardcourt2022generativeimaging,
author = {Woodward-Court, P and Keane, PA and Alexander, D and Zhou, Y},
month = {Jun},
number = {7},
publisher = {ASSOC RESEARCH VISION OPHTHALMOLOGY INC},
title = {Generative Adversarial Networks for OCT Counterfactual Visual Explanations in Ophthalmic Imaging},
url = {https://www.webofscience.com/api/gateway?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000844401300193\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=f41074198c063036414efcbc916f8956},
volume = {63},
year = {2022},
issn = {0146-0404},
eissn = {1552-5783},
keyword = {Science \& Technology},
keyword = {Life Sciences \& Biomedicine},
keyword = {Ophthalmology},
language = {English},
day = {1},
publicationstatus = {published},
}
@misc{zhou2022exploringpipeline,
author = {Zhou, Y and Wagner, S and Chia, M and Woodward-Court, P and Alexander, D and Keane, P},
month = {May},
organization = {Denver},
title = {Exploring Retinal Vascular Morphology via A Deep Learning Pipeline},
year = {2022},
abstract = {Purpose : Retinal vascular morphology provides valuable information for both ophthalmic disease and systemic disease (termed 'oculomics'), e.g., atherosclerosis and diabetes mellitus, in a rapid and non-invasive way. To help recognise high risk cases of ophthalmic and systemic disease through observing the changes of retinal vascular morphology, we propose a deep learning pipeline to automatically analyse the vascular morphology (AutoMorph) which measures 12 kinds of metrics, such as vessel calibre and tortuosity.

Methods : AutoMorph consists of four functional modules: image pre-processing, image quality grading, anatomical segmentation, including binary vessel, artery/vein, and optic disc/cup segmentation, and vascular morphology feature measurement. Image quality grading and anatomical segmentation use the most recent deep learning techniques and are trained on 12 public datasets, such as DRIVE, STARE, and CHASEDB1. We employ model ensemble strategy to achieve robust results and analyse the prediction confidence to rectify false gradable cases in image quality grading. We quantitatively validate module performance on 6 external publicly available datasets including EyePACS image quality dataset (EyePACS-Q), DDR, AV-WIDE, DR-HAGIS, IOSTAR-AV, and IDRID datasets.

Results : The EfficientNet-b4 architecture used in the image grading module achieves comparable performance to the state-of-the-art method in EyePACS-Q, with an F1-score of 0.86. The confidence analysis reduces 76\% of false gradable images. The binary vessel segmentation module achieves an F1-score of 0.73 on AV-WIDE and 0.78 on DR-HAGIS. The artery/vein module scores 0.66 on IOSTAR-AV, and optic disc/cup module achieves 0.94 in disc segmentation in IDRID. These results verify that AutoMorph performs well in external validation, being quantitatively on par or even better than some recent work in internal validation.

Conclusions : AutoMorph performs well even when the external validation data shows significant difference to the training data, e.g., validation on ultra-wide field retinal photography. The fully automatic pipeline integrates recent technical work to facilitate 'oculomics' research.},
startyear = {2022},
startmonth = {May},
startday = {1},
finishyear = {2022},
finishmonth = {May},
finishday = {4},
conference = {ARVO Annual Meeting},
day = {1},
}
@misc{xu2022learningsegmentation,
author = {Xu, M-C and Zhou, Y-K and Jin, C and Blumberg, SB and Wilson, FJ and deGroot, M and Alexander, DC and Oxtoby, NP and Jacob, J},
month = {Mar},
note = {To appear at Conference on Medical Imaging with Deep Learning (MIDL)
  2022. arXiv admin note: text overlap with arXiv:2110.12179},
title = {Learning Morphological Feature Perturbations for Calibrated
  Semi-Supervised Segmentation},
url = {http://arxiv.org/abs/2203.10196v2},
year = {2022},
abstract = {We propose MisMatch, a novel consistency-driven semi-supervised segmentation
framework which produces predictions that are invariant to learnt feature
perturbations. MisMatch consists of an encoder and a two-head decoders. One
decoder learns positive attention to the foreground regions of interest (RoI)
on unlabelled images thereby generating dilated features. The other decoder
learns negative attention to the foreground on the same unlabelled images
thereby generating eroded features. We then apply a consistency regularisation
on the paired predictions. MisMatch outperforms state-of-the-art
semi-supervised methods on a CT-based pulmonary vessel segmentation task and a
MRI-based brain tumour segmentation task. In addition, we show that the
effectiveness of MisMatch comes from better model calibration than its
supervised learning counterpart.},
keyword = {cs.CV},
keyword = {cs.CV},
keyword = {cs.AI},
keyword = {cs.LG},
day = {19},
}
@inproceedings{blumberg2022progressivemri,
author = {Blumberg, SB and Lin, H and Grussu, F and Zhou, Y and Figini, M and Alexander, DC},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
month = {Sep},
pages = {421--431},
title = {Progressive Subsampling for Oversampled Data - Application to Quantitative MRI},
volume = {13436 LNCS},
year = {2022},
abstract = {We present PROSUB: PROgressive SUBsampling, a deep learning based, automated methodology that subsamples an oversampled data set (e.g. channels of multi-channeled 3D images) with minimal loss of information. We build upon a state-of-the-art dual-network approach that won the MICCAI MUlti-DIffusion (MUDI) quantitative MRI (qMRI) measurement sampling-reconstruction challenge, but suffers from deep learning training instability, by subsampling with a hard decision boundary. PROSUB uses the paradigm of recursive feature elimination (RFE) and progressively subsamples measurements during deep learning training, improving optimization stability. PROSUB also integrates a neural architecture search (NAS) paradigm, allowing the network architecture hyperparameters to respond to the subsampling process. We show PROSUB outperforms the winner of the MUDI MICCAI challenge, producing large improvements \&gt; 18\% MSE on the MUDI challenge sub-tasks and qualitative improvements on downstream processes useful for clinical applications. We also show the benefits of incorporating NAS and analyze the effect of PROSUB’s components. As our method generalizes beyond MRI measurement selection-reconstruction, to problems that subsample and reconstruct multi-channeled data, our code is [7].},
doi = {10.1007/978-3-031-16446-0_40},
isbn = {9783031164453},
issn = {0302-9743},
eissn = {1611-3349},
conference = {International Conference on Medical Image Computing and Computer-Assisted Intervention  MICCAI 2022},
day = {17},
publicationstatus = {published},
}
@inproceedings{zhou2021learningimaging,
author = {Zhou, Y and Xu, M and Hu, Y and Lin, H and Jacob, J and Keane, PA and Alexander, DC},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
month = {Sep},
pages = {482--492},
title = {Learning to Address Intra-segment Misclassification in Retinal Imaging},
volume = {12901 LNCS},
year = {2021},
abstract = {Accurate multi-class segmentation is a long-standing challenge in medical imaging, especially in scenarios where classes share strong similarity. Segmenting retinal blood vessels in retinal photographs is one such scenario, in which arteries and veins need to be identified and differentiated from each other and from the background. Intra-segment misclassification, i.e. veins classified as arteries or vice versa, frequently occurs when arteries and veins intersect, whereas in binary retinal vessel segmentation, error rates are much lower. We thus propose a new approach that decomposes multi-class segmentation into multiple binary, followed by a binary-to-multi-class fusion network. The network merges representations of artery, vein, and multi-class feature maps, each of which are supervised by expert vessel annotation in adversarial training. A skip-connection based merging process explicitly maintains class-specific gradients to avoid gradient vanishing in deep layers, to favor the discriminative features. The results show that, our model respectively improves F1-score by 4.4\%, 5.1\%, and 4.2\% compared with three state-of-the-art deep learning based methods on DRIVE-AV, LES-AV, and HRF-AV data sets. Code: https://github.com/rmaphoh/Learning-AVSegmentation},
doi = {10.1007/978-3-030-87193-2_46},
isbn = {9783030871925},
issn = {0302-9743},
eissn = {1611-3349},
conference = {MICCAI 2021: Medical Image Computing and Computer Assisted Intervention},
day = {21},
publicationstatus = {published},
}
@inproceedings{lin2021generalisedexperts,
author = {Lin, H and Zhou, Y and Slator, P and Alexander, D},
booktitle = {Medical Image Computing and Computer Assisted Intervention – MICCAI 2021: 24th International Conference, Strasbourg, France, September 27–October 1, 2021, Proceedings, Part VI},
month = {Sep},
organization = {Strasbourg, France},
publisher = {Springer},
title = {Generalised Super Resolution for Quantitative MRI Using Self-supervised Mixture of Experts},
year = {2021},
doi = {10.1007/978-3-030-87231-1_5},
startyear = {2021},
startmonth = {Sep},
startday = {27},
finishyear = {2021},
finishmonth = {Oct},
finishday = {1},
conference = {MICCAI 2021},
day = {21},
}
@article{zhou2021asegmentation,
author = {Zhou, Y and Chen, Z and Shen, H and Zheng, X and Zhao, R and Duan, X},
journal = {Neurocomputing},
month = {May},
pages = {118--130},
publisher = {ELSEVIER},
title = {A refined equilibrium generative adversarial network for retinal vessel segmentation},
url = {http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000634377200011\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=f41074198c063036414efcbc916f8956},
volume = {437},
year = {2021},
doi = {10.1016/j.neucom.2020.06.143},
issn = {0925-2312},
eissn = {1872-8286},
keyword = {Science \& Technology},
keyword = {Technology},
keyword = {Computer Science, Artificial Intelligence},
keyword = {Computer Science},
keyword = {Retinal vessel segmentation},
keyword = {Symmetric adversarial architecture},
keyword = {Refine blocks},
keyword = {Attention mechanism},
language = {English},
day = {21},
publicationstatus = {published},
}
@inproceedings{chen2020improvingstructure,
author = {Chen, Z and Zheng, X and Shen, H and Zeng, Z and Zhou, Y and Zhao, R},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
month = {Jan},
pages = {205--219},
title = {Improving Knowledge Distillation via Category Structure},
volume = {12373 LNCS},
year = {2020},
abstract = {Most previous knowledge distillation frameworks train the student to mimic the teacher’s output of each sample or transfer cross-sample relations from the teacher to the student. Nevertheless, they neglect the structured relations at a category level. In this paper, a novel Category Structure is proposed to transfer category-level structured relations for knowledge distillation. It models two structured relations, including intra-category structure and inter-category structure, which are intrinsic natures in relations between samples. Intra-category structure penalizes the structured relations in samples from the same category and inter-category structure focuses on cross-category relations at a category level. Transferring category structure from the teacher to the student supplements category-level structured relations for training a better student. Extensive experiments show that our method groups samples from the same category tighter in the embedding space and the superiority of our method in comparison with closely related works are validated in different datasets and models.},
doi = {10.1007/978-3-030-58604-1_13},
issn = {0302-9743},
eissn = {1611-3349},
day = {1},
publicationstatus = {published},
}
@article{zhou2019geomagneticalgorithm,
author = {Zhou, Y and Huang, G and Zhang, X},
journal = {IEEE SENSORS JOURNAL},
month = {Dec},
number = {24},
pages = {12096--12104},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
title = {Geomagnetic Sensor Noise Reduction for Improving Calibration Compensation Accuracy Based on Improved HHT Algorithm},
volume = {19},
year = {2019},
doi = {10.1109/JSEN.2019.2940298},
issn = {1530-437X},
eissn = {1558-1748},
keyword = {Science \& Technology},
keyword = {Technology},
keyword = {Physical Sciences},
keyword = {Engineering, Electrical \& Electronic},
keyword = {Instruments \& Instrumentation},
keyword = {Physics, Applied},
keyword = {Engineering},
keyword = {Physics},
keyword = {Geomagnetic sensor},
keyword = {calibration compensation},
keyword = {noise error},
keyword = {attention Hilbert spectrum},
keyword = {similarity criterion},
keyword = {MAGNETOMETER CALIBRATION},
language = {English},
day = {15},
publicationstatus = {published},
}
@misc{zhou2019dualattentionlocalization,
author = {Zhou, Y and Chen, Z and Shen, H and Liu, Q and Zhao, R and Liang, Y},
month = {Sep},
note = {This work is licensed under an Attribution 4.0 International License (CC BY 4.0).},
publisher = {ArXiv},
title = {Dual-attention Focused Module for Weakly Supervised Object Localization},
url = {https://doi.org/10.48550/arXiv.1909.04813},
year = {2019},
abstract = {The research on recognizing the most discriminative regions provides referential information for weakly supervised object localization with only image-level annotations. However, the most discriminative regions usually conceal the other parts of the object, thereby impeding entire object recognition and localization. To tackle this problem, the Dual-attention Focused Module (DFM) is proposed to enhance object localization performance. Specifically, we present a dual attention module for information fusion, consisting of a position branch and a channel one. In each branch, the input feature map is deduced into an enhancement map and a mask map, thereby highlighting the most discriminative parts or hiding them. For the position mask map, we introduce a focused matrix to enhance it, which utilizes the principle that the pixels of an object are continuous. Between these two branches, the enhancement map is integrated with the mask map, aiming at partially compensating the lost information and diversifies the features. With the dual-attention module and focused matrix, the entire object region could be precisely recognized with implicit information. We demonstrate outperforming results of DFM in experiments. In particular, DFM achieves state-of-the-art performance in localization accuracy in ILSVRC 2016 and CUB-200-2011.},
language = {English},
day = {11},
publicationstatus = {published},
}
@article{zhou2018spinningsensor,
author = {Zhou, Y and Zhang, X and Xiao, W},
journal = {MEASUREMENT SCIENCE AND TECHNOLOGY},
month = {Sep},
number = {9},
publisher = {IOP PUBLISHING LTD},
title = {Spinning projectile's angular measurement using crest and trough data of a geomagnetic sensor},
url = {https://www.webofscience.com/api/gateway?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000440734200002\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=f41074198c063036414efcbc916f8956},
volume = {29},
year = {2018},
doi = {10.1088/1361-6501/aad0c7},
issn = {0957-0233},
eissn = {1361-6501},
keyword = {Science \& Technology},
keyword = {Technology},
keyword = {Engineering, Multidisciplinary},
keyword = {Instruments \& Instrumentation},
keyword = {Engineering},
keyword = {attitude measurement},
keyword = {geomagnetic sensor},
keyword = {simulation and experiment},
keyword = {ATTITUDE},
keyword = {CALIBRATION},
keyword = {ALGORITHM},
keyword = {DESIGN},
keyword = {FLIGHT},
language = {English},
day = {1},
publicationstatus = {published},
}
@article{zhou2018calibrationiteration,
author = {Zhou, Y and Zhang, X and Xiao, W},
journal = {JOURNAL OF INSTRUMENTATION},
month = {Apr},
number = {ARTN T04006},
publisher = {IOP Publishing Ltd},
title = {Calibration and compensation method of three-axis geomagnetic sensor based on pre-processing total least square iteration},
volume = {13},
year = {2018},
doi = {10.1088/1748-0221/13/04/T04006},
issn = {1748-0221},
keyword = {Science \& Technology},
keyword = {Technology},
keyword = {Instruments \& Instrumentation},
keyword = {Detector modelling and simulations II (electric fields charge transport multiplication and induction},
keyword = {pulse formation electron emission etc)},
keyword = {Instrument optimisation},
keyword = {Data Handling},
keyword = {Analysis and statistical methods},
language = {English},
publicationstatus = {published},
}
